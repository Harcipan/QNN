{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b4f856-efaf-48d5-8553-6093487bf271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== QCNN sweep with configurable n_qubits + CSV saving ====\n",
    "import json, time, csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.circuit.library import ZFeatureMap\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.primitives import StatevectorEstimator as Estimator\n",
    "\n",
    "from qiskit_machine_learning.utils import algorithm_globals\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "from qiskit_machine_learning.optimizers import COBYLA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def _require_power_of_two(n):\n",
    "    if n < 2 or (n & (n - 1)) != 0:\n",
    "        raise ValueError(f\"n_qubits must be a power of two >= 2, got {n}\")\n",
    "\n",
    "# -------------------------\n",
    "# Building blocks (conv/pool)\n",
    "# -------------------------\n",
    "def conv_circuit(params):\n",
    "    target = QuantumCircuit(2)\n",
    "    target.rz(-np.pi / 2, 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(params[0], 0)\n",
    "    target.ry(params[1], 1)\n",
    "    target.cx(0, 1)\n",
    "    target.ry(params[2], 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(np.pi / 2, 0)\n",
    "    return target\n",
    "\n",
    "def conv_layer(num_qubits, param_prefix):\n",
    "    qc = QuantumCircuit(num_qubits, name=\"Convolutional Layer\")\n",
    "    qubits = list(range(num_qubits))\n",
    "    param_index = 0\n",
    "    params = ParameterVector(param_prefix, length=num_qubits * 3)\n",
    "\n",
    "    # even-odd pairs\n",
    "    for q1, q2 in zip(qubits[0::2], qubits[1::2]):\n",
    "        qc = qc.compose(conv_circuit(params[param_index : param_index + 3]), [q1, q2])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "\n",
    "    # odd-next (with wrap) pairs\n",
    "    for q1, q2 in zip(qubits[1::2], qubits[2::2] + [0]):\n",
    "        qc = qc.compose(conv_circuit(params[param_index : param_index + 3]), [q1, q2])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "\n",
    "    qc_inst = qc.to_instruction()\n",
    "    qc2 = QuantumCircuit(num_qubits)\n",
    "    qc2.append(qc_inst, qubits)\n",
    "    return qc2\n",
    "\n",
    "def pool_circuit(params):\n",
    "    target = QuantumCircuit(2)\n",
    "    target.rz(-np.pi / 2, 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(params[0], 0)\n",
    "    target.ry(params[1], 1)\n",
    "    target.cx(0, 1)\n",
    "    target.ry(params[2], 1)\n",
    "    return target\n",
    "\n",
    "def pool_layer(sources, sinks, param_prefix):\n",
    "    num_qubits = len(sources) + len(sinks)\n",
    "    qc = QuantumCircuit(num_qubits, name=\"Pooling Layer\")\n",
    "    param_index = 0\n",
    "    params = ParameterVector(param_prefix, length=(num_qubits // 2) * 3)\n",
    "\n",
    "    for source, sink in zip(sources, sinks):\n",
    "        qc = qc.compose(pool_circuit(params[param_index : param_index + 3]), [source, sink])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "\n",
    "    qc_inst = qc.to_instruction()\n",
    "    qc2 = QuantumCircuit(num_qubits)\n",
    "    qc2.append(qc_inst, range(num_qubits))\n",
    "    return qc2\n",
    "\n",
    "# -------------------------\n",
    "# Data generation for n_qubits\n",
    "#  - uses a 2 x (n_qubits/2) grid\n",
    "#  - labels: horizontal pair = -1, vertical pair = +1\n",
    "# -------------------------\n",
    "def generate_dataset(num_images, n_qubits):\n",
    "    _require_power_of_two(n_qubits)\n",
    "    if n_qubits % 2 != 0:\n",
    "        raise ValueError(\"n_qubits must be even (for 2-row grid).\")\n",
    "\n",
    "    width = n_qubits // 2  # 2 rows\n",
    "    images, labels = [], []\n",
    "\n",
    "    # Precompute horizontal patterns: two adjacent cells in a row (no wrap)\n",
    "    # total = 2 * (width - 1)\n",
    "    hor_patterns = []\n",
    "    for row in range(2):\n",
    "        base = row * width\n",
    "        for c in range(width - 1):\n",
    "            v = np.zeros(n_qubits)\n",
    "            v[base + c] = np.pi / 2\n",
    "            v[base + c + 1] = np.pi / 2\n",
    "            hor_patterns.append(v)\n",
    "\n",
    "    # Precompute vertical patterns: same column across two rows\n",
    "    # total = width\n",
    "    ver_patterns = []\n",
    "    for c in range(width):\n",
    "        v = np.zeros(n_qubits)\n",
    "        v[c] = np.pi / 2\n",
    "        v[c + width] = np.pi / 2\n",
    "        ver_patterns.append(v)\n",
    "\n",
    "    for _ in range(num_images):\n",
    "        rng = algorithm_globals.random.integers(0, 2)\n",
    "        if rng == 0:\n",
    "            labels.append(-1)\n",
    "            idx = algorithm_globals.random.integers(0, len(hor_patterns))\n",
    "            images.append(hor_patterns[idx].copy())\n",
    "        else:\n",
    "            labels.append(1)\n",
    "            idx = algorithm_globals.random.integers(0, len(ver_patterns))\n",
    "            images.append(ver_patterns[idx].copy())\n",
    "\n",
    "        # add noise to zeros only\n",
    "        for k in range(n_qubits):\n",
    "            if images[-1][k] == 0:\n",
    "                images[-1][k] = algorithm_globals.random.uniform(0, np.pi / 4)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# -------------------------\n",
    "# Build QCNN for arbitrary n_qubits (power of two), measuring the final pooled qubit\n",
    "# -------------------------\n",
    "def build_qcnn(estimator, n_qubits):\n",
    "    _require_power_of_two(n_qubits)\n",
    "\n",
    "    feature_map = ZFeatureMap(n_qubits)\n",
    "\n",
    "    ansatz = QuantumCircuit(n_qubits, name=\"Ansatz\")\n",
    "\n",
    "    # \"active\" holds the absolute indices of the current working block\n",
    "    active = list(range(n_qubits))\n",
    "    stage = 1\n",
    "    while len(active) > 1:\n",
    "        # Convolution over the active block\n",
    "        ansatz.compose(conv_layer(len(active), f\"c{stage}\"), active, inplace=True)\n",
    "\n",
    "        # Pool first half into second half within the active block\n",
    "        half = len(active) // 2\n",
    "        sources_local = list(range(0, half))\n",
    "        sinks_local   = list(range(half, len(active)))\n",
    "        ansatz.compose(pool_layer(sources_local, sinks_local, f\"p{stage}\"), active, inplace=True)\n",
    "\n",
    "        # Next stage works on the sinks (second half)\n",
    "        active = active[half:]\n",
    "        stage += 1\n",
    "\n",
    "    readout_qubit = active[0]  # single remaining qubit\n",
    "    # Construct observable with Z on readout, I elsewhere\n",
    "    obs = [\"I\"] * n_qubits\n",
    "    obs[readout_qubit] = \"Z\"\n",
    "    observable = SparsePauliOp.from_list([(\"\".join(obs), 1)])\n",
    "\n",
    "    circuit = QuantumCircuit(n_qubits)\n",
    "    circuit.compose(feature_map, range(n_qubits), inplace=True)\n",
    "    circuit.compose(ansatz, range(n_qubits), inplace=True)\n",
    "\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=circuit.decompose(),\n",
    "        observables=observable,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        estimator=estimator,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "# -------------------------\n",
    "# One trial\n",
    "# -------------------------\n",
    "def run_trial(seed, n_qubits=8, num_images=200, maxiter=200, estimator=None, dataset=None,\n",
    "              split_random_state=None, optimizer_kind=\"COBYLA\"):\n",
    "    _require_power_of_two(n_qubits)\n",
    "    algorithm_globals.random_seed = int(seed)\n",
    "    rng = np.random.default_rng(int(seed))\n",
    "\n",
    "    # dataset (fresh or fixed)\n",
    "    if dataset is None:\n",
    "        images, labels = generate_dataset(num_images, n_qubits)\n",
    "    else:\n",
    "        images, labels = dataset\n",
    "\n",
    "    rs = split_random_state if split_random_state is not None else int(seed)\n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(\n",
    "        images, labels, test_size=0.30, random_state=rs, stratify=labels\n",
    "    )\n",
    "\n",
    "    qnn = build_qcnn(estimator or Estimator(), n_qubits)\n",
    "    init = rng.uniform(-np.pi, np.pi, qnn.num_weights)\n",
    "\n",
    "    # pick optimizer\n",
    "    if optimizer_kind == \"COBYLA\":\n",
    "        optimizer = COBYLA(maxiter=maxiter)\n",
    "    else:\n",
    "        try:\n",
    "            from qiskit_algorithms.optimizers import SPSA, L_BFGS_B\n",
    "        except Exception:\n",
    "            from qiskit.algorithms.optimizers import SPSA, L_BFGS_B\n",
    "        optimizer = {\"SPSA\": SPSA(maxiter=maxiter),\n",
    "                     \"L_BFGS_B\": L_BFGS_B(maxiter=maxiter)}.get(optimizer_kind, COBYLA(maxiter=maxiter))\n",
    "\n",
    "    clf = NeuralNetworkClassifier(qnn, optimizer=optimizer, initial_point=init, callback=None)\n",
    "\n",
    "    xtr, ytr = np.asarray(x_tr), np.asarray(y_tr)\n",
    "    clf.fit(xtr, ytr)\n",
    "\n",
    "    train_acc = float(clf.score(xtr, ytr))\n",
    "    xte, yte = np.asarray(x_te), np.asarray(y_te)\n",
    "    test_acc  = float(clf.score(xte, yte))\n",
    "\n",
    "    return {\"seed\": int(seed), \"train_acc\": train_acc, \"test_acc\": test_acc}\n",
    "\n",
    "# -------------------------\n",
    "# Many trials + histogram + CSV\n",
    "# -------------------------\n",
    "def run_many(n_trials=10, n_qubits=8, num_images=200, maxiter=200, vary_dataset=True, vary_split=True,\n",
    "             optimizer_kind=\"COBYLA\", save_csv_path=None, show_hist=True):\n",
    "    _require_power_of_two(n_qubits)\n",
    "    est = Estimator()\n",
    "    results = []\n",
    "\n",
    "    fixed_dataset = None\n",
    "    if not vary_dataset:\n",
    "        fixed_dataset = generate_dataset(num_images, n_qubits)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for i in range(n_trials):\n",
    "        seed = 10000 + i\n",
    "        dataset = None if vary_dataset else fixed_dataset\n",
    "        split_rs = (seed if vary_split else 246)\n",
    "        res = run_trial(seed, n_qubits, num_images, maxiter, est, dataset, split_rs, optimizer_kind)\n",
    "        results.append(res)\n",
    "        print(f\"[{i+1}/{n_trials}] seed={seed} train={res['train_acc']:.3f} test={res['test_acc']:.3f}\")\n",
    "\n",
    "    test_accs = np.array([r[\"test_acc\"] for r in results])\n",
    "    train_accs = np.array([r[\"train_acc\"] for r in results])\n",
    "\n",
    "    print(f\"\\nTrials: {n_trials} | elapsed: {time.time()-t0:.1f}s\")\n",
    "    print(f\"Test acc  mean={test_accs.mean():.3f}  std={test_accs.std(ddof=1):.3f}  \"\n",
    "          f\"min={test_accs.min():.3f}  max={test_accs.max():.3f}\")\n",
    "    print(f\"Train acc mean={train_accs.mean():.3f}  std={train_accs.std(ddof=1):.3f}  \"\n",
    "          f\"min={train_accs.min():.3f}  max={train_accs.max():.3f}\")\n",
    "\n",
    "    if show_hist:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.hist(test_accs, bins=10)\n",
    "        plt.xlabel(\"Test Accuracy\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(f\"Distribution of Test Accuracy (n={n_trials}, {n_qubits} qubits)\")\n",
    "        plt.show()\n",
    "\n",
    "    # --- CSV save ---\n",
    "    if save_csv_path:\n",
    "        fieldnames = [\"trial\", \"seed\", \"train_acc\", \"test_acc\",\n",
    "                      \"n_qubits\", \"num_images\", \"maxiter\", \"vary_dataset\", \"vary_split\", \"optimizer\"]\n",
    "        with open(save_csv_path, \"w\", newline=\"\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            w.writeheader()\n",
    "            for i, r in enumerate(results, start=1):\n",
    "                w.writerow({\n",
    "                    \"trial\": i,\n",
    "                    \"seed\": r[\"seed\"],\n",
    "                    \"train_acc\": float(r[\"train_acc\"]),\n",
    "                    \"test_acc\": float(r[\"test_acc\"]),\n",
    "                    \"n_qubits\": int(n_qubits),\n",
    "                    \"num_images\": int(num_images),\n",
    "                    \"maxiter\": int(maxiter),\n",
    "                    \"vary_dataset\": bool(vary_dataset),\n",
    "                    \"vary_split\": bool(vary_split),\n",
    "                    \"optimizer\": str(optimizer_kind),\n",
    "                })\n",
    "        print(f\"Saved results to {save_csv_path}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444ffae-3058-4789-9da2-4102eab2292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] seed=10000 train=0.514 test=0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/3] seed=10001 train=0.529 test=0.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
     ]
    }
   ],
   "source": [
    "results = run_many(\n",
    "    n_trials=3, n_qubits=16, num_images=200, maxiter=50,\n",
    "    vary_dataset=True, vary_split=True,\n",
    "    save_csv_path=\"16qbit_50iter.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba15e2-bf27-488f-87f4-520554169d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
