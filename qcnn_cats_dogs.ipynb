{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80201d8-de5d-4a82-9874-102826fd71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== QCNN with cats vs dogs dataset ====\n",
    "import os, glob, json, time, csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import kagglehub\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.circuit.library import ZFeatureMap\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.primitives import StatevectorEstimator as Estimator\n",
    "\n",
    "from qiskit_machine_learning.utils import algorithm_globals\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "from qiskit_machine_learning.optimizers import COBYLA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def _require_power_of_two(n):\n",
    "    if n < 2 or (n & (n - 1)) != 0:\n",
    "        raise ValueError(f\"n_qubits must be a power of two >= 2, got {n}\")\n",
    "\n",
    "# -------------------------\n",
    "# Building blocks (conv/pool)\n",
    "# -------------------------\n",
    "def conv_circuit(params):\n",
    "    target = QuantumCircuit(2)\n",
    "    target.rz(-np.pi / 2, 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(params[0], 0)\n",
    "    target.ry(params[1], 1)\n",
    "    target.cx(0, 1)\n",
    "    target.ry(params[2], 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(np.pi / 2, 0)\n",
    "    return target\n",
    "\n",
    "def conv_layer(num_qubits, param_prefix):\n",
    "    qc = QuantumCircuit(num_qubits, name=\"Convolutional Layer\")\n",
    "    qubits = list(range(num_qubits))\n",
    "    param_index = 0\n",
    "    params = ParameterVector(param_prefix, length=num_qubits * 3)\n",
    "    for q1, q2 in zip(qubits[0::2], qubits[1::2]):\n",
    "        qc = qc.compose(conv_circuit(params[param_index : param_index + 3]), [q1, q2])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "    for q1, q2 in zip(qubits[1::2], qubits[2::2] + [0]):\n",
    "        qc = qc.compose(conv_circuit(params[param_index : param_index + 3]), [q1, q2])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "    qc_inst = qc.to_instruction()\n",
    "    qc2 = QuantumCircuit(num_qubits)\n",
    "    qc2.append(qc_inst, qubits)\n",
    "    return qc2\n",
    "\n",
    "def pool_circuit(params):\n",
    "    target = QuantumCircuit(2)\n",
    "    target.rz(-np.pi / 2, 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(params[0], 0)\n",
    "    target.ry(params[1], 1)\n",
    "    target.cx(0, 1)\n",
    "    target.ry(params[2], 1)\n",
    "    return target\n",
    "\n",
    "def pool_layer(sources, sinks, param_prefix):\n",
    "    num_qubits = len(sources) + len(sinks)\n",
    "    qc = QuantumCircuit(num_qubits, name=\"Pooling Layer\")\n",
    "    param_index = 0\n",
    "    params = ParameterVector(param_prefix, length=(num_qubits // 2) * 3)\n",
    "    for source, sink in zip(sources, sinks):\n",
    "        qc = qc.compose(pool_circuit(params[param_index : param_index + 3]), [source, sink])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "    qc_inst = qc.to_instruction()\n",
    "    qc2 = QuantumCircuit(num_qubits)\n",
    "    qc2.append(qc_inst, range(num_qubits))\n",
    "    return qc2\n",
    "\n",
    "# -------------------------\n",
    "# Build QCNN for arbitrary n_qubits\n",
    "# -------------------------\n",
    "def build_qcnn(estimator, n_qubits):\n",
    "    _require_power_of_two(n_qubits)\n",
    "    feature_map = ZFeatureMap(n_qubits)\n",
    "    ansatz = QuantumCircuit(n_qubits, name=\"Ansatz\")\n",
    "    active = list(range(n_qubits))\n",
    "    stage = 1\n",
    "    while len(active) > 1:\n",
    "        ansatz.compose(conv_layer(len(active), f\"c{stage}\"), active, inplace=True)\n",
    "        half = len(active) // 2\n",
    "        sources_local = list(range(0, half))\n",
    "        sinks_local   = list(range(half, len(active)))\n",
    "        ansatz.compose(pool_layer(sources_local, sinks_local, f\"p{stage}\"), active, inplace=True)\n",
    "        active = active[half:]\n",
    "        stage += 1\n",
    "    readout_qubit = active[0]\n",
    "    obs = [\"I\"] * n_qubits\n",
    "    obs[readout_qubit] = \"Z\"\n",
    "    observable = SparsePauliOp.from_list([(\"\".join(obs), 1)])\n",
    "    circuit = QuantumCircuit(n_qubits)\n",
    "    circuit.compose(feature_map, range(n_qubits), inplace=True)\n",
    "    circuit.compose(ansatz, range(n_qubits), inplace=True)\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=circuit.decompose(),\n",
    "        observables=observable,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        estimator=estimator,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "# -------------------------\n",
    "# Trial\n",
    "# -------------------------\n",
    "def run_trial(seed, n_qubits=8, maxiter=200, estimator=None,\n",
    "              dataset=None, split_random_state=None, optimizer_kind=\"COBYLA\"):\n",
    "    _require_power_of_two(n_qubits)\n",
    "    algorithm_globals.random_seed = int(seed)\n",
    "    rng = np.random.default_rng(int(seed))\n",
    "    images, labels = dataset\n",
    "    rs = split_random_state if split_random_state is not None else int(seed)\n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(\n",
    "        images, labels, test_size=0.30, random_state=rs, stratify=labels\n",
    "    )\n",
    "    qnn = build_qcnn(estimator or Estimator(), n_qubits)\n",
    "    init = rng.uniform(-np.pi, np.pi, qnn.num_weights)\n",
    "    if optimizer_kind == \"COBYLA\":\n",
    "        optimizer = COBYLA(maxiter=maxiter)\n",
    "    else:\n",
    "        from qiskit.algorithms.optimizers import SPSA, L_BFGS_B\n",
    "        optimizer = {\"SPSA\": SPSA(maxiter=maxiter),\n",
    "                     \"L_BFGS_B\": L_BFGS_B(maxiter=maxiter)}.get(optimizer_kind, COBYLA(maxiter=maxiter))\n",
    "    clf = NeuralNetworkClassifier(qnn, optimizer=optimizer, initial_point=init, callback=None)\n",
    "    xtr, ytr = np.asarray(x_tr), np.asarray(y_tr)\n",
    "    clf.fit(xtr, ytr)\n",
    "    train_acc = float(clf.score(xtr, ytr))\n",
    "    xte, yte = np.asarray(x_te), np.asarray(y_te)\n",
    "    test_acc  = float(clf.score(xte, yte))\n",
    "    return {\"seed\": int(seed), \"train_acc\": train_acc, \"test_acc\": test_acc}\n",
    "\n",
    "# -------------------------\n",
    "# Run many trials\n",
    "# -------------------------\n",
    "def run_many_with_dataset(dataset, n_trials=5, n_qubits=8, maxiter=200,\n",
    "                          vary_split=True, optimizer_kind=\"COBYLA\",\n",
    "                          save_csv_path=None, show_hist=True):\n",
    "    _require_power_of_two(n_qubits)\n",
    "    est = Estimator()\n",
    "    results = []\n",
    "    t0 = time.time()\n",
    "    for i in range(n_trials):\n",
    "        seed = 10000 + i\n",
    "        res = run_trial(\n",
    "            seed=seed,\n",
    "            n_qubits=n_qubits,\n",
    "            maxiter=maxiter,\n",
    "            estimator=est,\n",
    "            dataset=dataset,\n",
    "            split_random_state=(seed if vary_split else 246),\n",
    "            optimizer_kind=optimizer_kind\n",
    "        )\n",
    "        results.append(res)\n",
    "        print(f\"[{i+1}/{n_trials}] seed={seed} train={res['train_acc']:.3f} test={res['test_acc']:.3f}\")\n",
    "    test_accs  = np.array([r[\"test_acc\"] for r in results])\n",
    "    train_accs = np.array([r[\"train_acc\"] for r in results])\n",
    "    print(f\"\\nTrials: {n_trials} | elapsed: {time.time()-t0:.1f}s\")\n",
    "    print(f\"Test acc  mean={test_accs.mean():.3f}  std={test_accs.std(ddof=1):.3f}  \"\n",
    "          f\"min={test_accs.min():.3f}  max={test_accs.max():.3f}\")\n",
    "    print(f\"Train acc mean={train_accs.mean():.3f}  std={train_accs.std(ddof=1):.3f}  \"\n",
    "          f\"min={train_accs.min():.3f}  max={train_accs.max():.3f}\")\n",
    "    if show_hist:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.hist(test_accs, bins=10)\n",
    "        plt.xlabel(\"Test Accuracy\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(f\"Distribution of Test Accuracy (n={n_trials}, {n_qubits} qubits)\")\n",
    "        plt.show()\n",
    "    if save_csv_path:\n",
    "        fieldnames = [\"trial\", \"seed\", \"train_acc\", \"test_acc\",\n",
    "                      \"n_qubits\", \"maxiter\", \"optimizer\"]\n",
    "        with open(save_csv_path, \"w\", newline=\"\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            w.writeheader()\n",
    "            for i, r in enumerate(results, start=1):\n",
    "                w.writerow({\n",
    "                    \"trial\": i, \"seed\": r[\"seed\"],\n",
    "                    \"train_acc\": float(r[\"train_acc\"]), \"test_acc\": float(r[\"test_acc\"]),\n",
    "                    \"n_qubits\": int(n_qubits),\n",
    "                    \"maxiter\": int(maxiter),\n",
    "                    \"optimizer\": str(optimizer_kind),\n",
    "                })\n",
    "        print(f\"Saved results to {save_csv_path}\")\n",
    "    return results\n",
    "\n",
    "# -------------------------\n",
    "# Image loader for cats vs dogs\n",
    "# -------------------------\n",
    "def _img_to_features(path, n_qubits):\n",
    "    with Image.open(path) as im:\n",
    "        im = im.convert(\"L\")\n",
    "        im = im.resize((n_qubits, 1), Image.BILINEAR)\n",
    "        v = np.asarray(im, dtype=np.float32).reshape(-1)\n",
    "    return (v / 255.0) * np.pi\n",
    "\n",
    "def _find_class_dirs(root, class_aliases):\n",
    "    matches = []\n",
    "    aliases = {a.lower() for a in class_aliases}\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        leaf = os.path.basename(dirpath).lower()\n",
    "        if leaf in aliases:\n",
    "            for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.gif\",\"*.webp\",\"*.tif\",\"*.tiff\"):\n",
    "                if glob.glob(os.path.join(dirpath, ext)):\n",
    "                    matches.append(dirpath)\n",
    "                    break\n",
    "    return matches\n",
    "\n",
    "def _collect_images(folder):\n",
    "    files = []\n",
    "    for ext in (\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.bmp\",\"*.gif\",\"*.webp\",\"*.tif\",\"*.tiff\"):\n",
    "        files += glob.glob(os.path.join(folder, ext))\n",
    "    return sorted(files)\n",
    "\n",
    "def load_cats_dogs_auto(root_dir, n_qubits, limit_per_class=None, shuffle=True):\n",
    "    _require_power_of_two(n_qubits)\n",
    "    cat_dirs = _find_class_dirs(root_dir, {\"cat\",\"cats\"})\n",
    "    dog_dirs = _find_class_dirs(root_dir, {\"dog\",\"dogs\"})\n",
    "    if not cat_dirs or not dog_dirs:\n",
    "        raise FileNotFoundError(f\"Couldn’t locate 'cats' and 'dogs' folders under: {root_dir}\")\n",
    "    cat_files = []\n",
    "    for d in cat_dirs: cat_files += _collect_images(d)\n",
    "    dog_files = []\n",
    "    for d in dog_dirs: dog_files += _collect_images(d)\n",
    "    if limit_per_class is not None:\n",
    "        cat_files = cat_files[:limit_per_class]\n",
    "        dog_files = dog_files[:limit_per_class]\n",
    "    images, labels = [], []\n",
    "    for p in cat_files:\n",
    "        try:\n",
    "            images.append(_img_to_features(p, n_qubits)); labels.append(-1)\n",
    "        except: pass\n",
    "    for p in dog_files:\n",
    "        try:\n",
    "            images.append(_img_to_features(p, n_qubits)); labels.append(+1)\n",
    "        except: pass\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng(42)\n",
    "        idx = np.arange(len(images)); rng.shuffle(idx)\n",
    "        images = [images[i] for i in idx]\n",
    "        labels = [int(labels[i]) for i in idx]\n",
    "    return images, labels\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Download dataset\n",
    "    path = kagglehub.dataset_download(\"bhavikjikadara/dog-and-cat-classification-dataset\")\n",
    "    print(\"Path to dataset files:\", path)\n",
    "\n",
    "    n_qubits = 8      # must be power of two\n",
    "    limit    = 500    # images per class cap\n",
    "\n",
    "    dataset = load_cats_dogs_auto(path, n_qubits=n_qubits, limit_per_class=limit)\n",
    "    cats = sum(1 for y in dataset[1] if y == -1)\n",
    "    dogs = sum(1 for y in dataset[1] if y == +1)\n",
    "    print(f\"Loaded images — cats: {cats}, dogs: {dogs}, total: {len(dataset[1])}\")\n",
    "\n",
    "    results = run_many_with_dataset(\n",
    "        dataset,\n",
    "        n_trials=3,\n",
    "        n_qubits=n_qubits,\n",
    "        maxiter=50,  # reduce for demo\n",
    "        vary_split=True,\n",
    "        optimizer_kind=\"COBYLA\",\n",
    "        save_csv_path=\"qcnn_cats_dogs_results.csv\",\n",
    "        show_hist=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5902c8e-507b-40a8-bbb2-6c2e5a5873b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "from PIL import Image\n",
    "def _img_to_features(path, n_qubits):\n",
    "    \"\"\"\n",
    "    Load an image, make it grayscale, compress to 1 x n_qubits,\n",
    "    flatten to length n_qubits in [0, pi].\n",
    "    \"\"\"\n",
    "    with Image.open(path) as im:\n",
    "        im = im.convert(\"L\")                  # grayscale\n",
    "        # compress to a 1 × n_qubits strip (works for any power-of-two n_qubits)\n",
    "        im = im.resize((n_qubits, 1), Image.BILINEAR)\n",
    "        v = np.asarray(im, dtype=np.float32).reshape(-1)  # length n_qubits, range 0..255\n",
    "    v = v / 255.0                             # 0..1\n",
    "    return v * np.pi                          # 0..π  (nice for ZFeatureMap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c9c53-3978-44d3-ab57-d78959694877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cats_dogs_dataset(root_dir, n_qubits, limit_per_class=None, shuffle=True):\n",
    "    \"\"\"\n",
    "    Expects a directory like:\n",
    "      root_dir/\n",
    "        cats/  *.jpg|*.png|...\n",
    "        dogs/  *.jpg|*.png|...\n",
    "\n",
    "    Returns (images, labels) where images is a list of length-n_qubits arrays\n",
    "    and labels are -1 for 'cats', +1 for 'dogs'.\n",
    "    \"\"\"\n",
    "    _require_power_of_two(n_qubits)\n",
    "\n",
    "    def _collect(sub):\n",
    "        # accept multiple image extensions\n",
    "        pats = []\n",
    "        for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.gif\", \"*.webp\", \"*.tif\", \"*.tiff\"):\n",
    "            pats += glob.glob(os.path.join(root_dir, sub, ext))\n",
    "        return sorted(pats)\n",
    "\n",
    "    # be flexible about folder names\n",
    "    candidates = {\n",
    "        \"cats\":  (\"cat\", \"cats\"),\n",
    "        \"dogs\":  (\"dog\", \"dogs\"),\n",
    "    }\n",
    "    def _find_subdir(names):\n",
    "        for name in names:\n",
    "            p = os.path.join(root_dir, name)\n",
    "            if os.path.isdir(p):\n",
    "                return name\n",
    "        return None\n",
    "\n",
    "    cats_dir = _find_subdir(candidates[\"cats\"])\n",
    "    dogs_dir = _find_subdir(candidates[\"dogs\"])\n",
    "    if cats_dir is None or dogs_dir is None:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Could not find 'cats' and 'dogs' subfolders under {root_dir}. \"\n",
    "            f\"Found cats={cats_dir}, dogs={dogs_dir}.\"\n",
    "        )\n",
    "\n",
    "    cat_files = _collect(cats_dir)\n",
    "    dog_files = _collect(dogs_dir)\n",
    "\n",
    "    if limit_per_class is not None:\n",
    "        cat_files = cat_files[:limit_per_class]\n",
    "        dog_files = dog_files[:limit_per_class]\n",
    "\n",
    "    images, labels = [], []\n",
    "    for path in cat_files:\n",
    "        try:\n",
    "            images.append(_img_to_features(path, n_qubits))\n",
    "            labels.append(-1)  # keep your label convention\n",
    "        except Exception:\n",
    "            continue  # skip unreadable images\n",
    "\n",
    "    for path in dog_files:\n",
    "        try:\n",
    "            images.append(_img_to_features(path, n_qubits))\n",
    "            labels.append(+1)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    images = [np.asarray(x, dtype=np.float32) for x in images]\n",
    "    labels = [int(y) for y in labels]\n",
    "\n",
    "    if shuffle:\n",
    "        rng = np.random.default_rng(12345)\n",
    "        idx = np.arange(len(images))\n",
    "        rng.shuffle(idx)\n",
    "        images = [images[i] for i in idx]\n",
    "        labels = [labels[i] for i in idx]\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b4f856-efaf-48d5-8553-6093487bf271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== QCNN sweep with configurable n_qubits + CSV saving ====\n",
    "import json, time, csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.circuit.library import ZFeatureMap\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.primitives import StatevectorEstimator as Estimator\n",
    "\n",
    "from qiskit_machine_learning.utils import algorithm_globals\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "from qiskit_machine_learning.optimizers import COBYLA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def _require_power_of_two(n):\n",
    "    if n < 2 or (n & (n - 1)) != 0:\n",
    "        raise ValueError(f\"n_qubits must be a power of two >= 2, got {n}\")\n",
    "\n",
    "# -------------------------\n",
    "# Building blocks (conv/pool)\n",
    "# -------------------------\n",
    "def conv_circuit(params):\n",
    "    target = QuantumCircuit(2)\n",
    "    target.rz(-np.pi / 2, 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(params[0], 0)\n",
    "    target.ry(params[1], 1)\n",
    "    target.cx(0, 1)\n",
    "    target.ry(params[2], 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(np.pi / 2, 0)\n",
    "    return target\n",
    "\n",
    "def conv_layer(num_qubits, param_prefix):\n",
    "    qc = QuantumCircuit(num_qubits, name=\"Convolutional Layer\")\n",
    "    qubits = list(range(num_qubits))\n",
    "    param_index = 0\n",
    "    params = ParameterVector(param_prefix, length=num_qubits * 3)\n",
    "\n",
    "    # even-odd pairs\n",
    "    for q1, q2 in zip(qubits[0::2], qubits[1::2]):\n",
    "        qc = qc.compose(conv_circuit(params[param_index : param_index + 3]), [q1, q2])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "\n",
    "    # odd-next (with wrap) pairs\n",
    "    for q1, q2 in zip(qubits[1::2], qubits[2::2] + [0]):\n",
    "        qc = qc.compose(conv_circuit(params[param_index : param_index + 3]), [q1, q2])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "\n",
    "    qc_inst = qc.to_instruction()\n",
    "    qc2 = QuantumCircuit(num_qubits)\n",
    "    qc2.append(qc_inst, qubits)\n",
    "    return qc2\n",
    "\n",
    "def pool_circuit(params):\n",
    "    target = QuantumCircuit(2)\n",
    "    target.rz(-np.pi / 2, 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(params[0], 0)\n",
    "    target.ry(params[1], 1)\n",
    "    target.cx(0, 1)\n",
    "    target.ry(params[2], 1)\n",
    "    return target\n",
    "\n",
    "def pool_layer(sources, sinks, param_prefix):\n",
    "    num_qubits = len(sources) + len(sinks)\n",
    "    qc = QuantumCircuit(num_qubits, name=\"Pooling Layer\")\n",
    "    param_index = 0\n",
    "    params = ParameterVector(param_prefix, length=(num_qubits // 2) * 3)\n",
    "\n",
    "    for source, sink in zip(sources, sinks):\n",
    "        qc = qc.compose(pool_circuit(params[param_index : param_index + 3]), [source, sink])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "\n",
    "    qc_inst = qc.to_instruction()\n",
    "    qc2 = QuantumCircuit(num_qubits)\n",
    "    qc2.append(qc_inst, range(num_qubits))\n",
    "    return qc2\n",
    "\n",
    "# -------------------------\n",
    "# Data generation for n_qubits\n",
    "#  - uses a 2 x (n_qubits/2) grid\n",
    "#  - labels: horizontal pair = -1, vertical pair = +1\n",
    "# -------------------------\n",
    "def generate_dataset(num_images, n_qubits):\n",
    "    _require_power_of_two(n_qubits)\n",
    "    if n_qubits % 2 != 0:\n",
    "        raise ValueError(\"n_qubits must be even (for 2-row grid).\")\n",
    "\n",
    "    width = n_qubits // 2  # 2 rows\n",
    "    images, labels = [], []\n",
    "\n",
    "    # Precompute horizontal patterns: two adjacent cells in a row (no wrap)\n",
    "    # total = 2 * (width - 1)\n",
    "    hor_patterns = []\n",
    "    for row in range(2):\n",
    "        base = row * width\n",
    "        for c in range(width - 1):\n",
    "            v = np.zeros(n_qubits)\n",
    "            v[base + c] = np.pi / 2\n",
    "            v[base + c + 1] = np.pi / 2\n",
    "            hor_patterns.append(v)\n",
    "\n",
    "    # Precompute vertical patterns: same column across two rows\n",
    "    # total = width\n",
    "    ver_patterns = []\n",
    "    for c in range(width):\n",
    "        v = np.zeros(n_qubits)\n",
    "        v[c] = np.pi / 2\n",
    "        v[c + width] = np.pi / 2\n",
    "        ver_patterns.append(v)\n",
    "\n",
    "    for _ in range(num_images):\n",
    "        rng = algorithm_globals.random.integers(0, 2)\n",
    "        if rng == 0:\n",
    "            labels.append(-1)\n",
    "            idx = algorithm_globals.random.integers(0, len(hor_patterns))\n",
    "            images.append(hor_patterns[idx].copy())\n",
    "        else:\n",
    "            labels.append(1)\n",
    "            idx = algorithm_globals.random.integers(0, len(ver_patterns))\n",
    "            images.append(ver_patterns[idx].copy())\n",
    "\n",
    "        # add noise to zeros only\n",
    "        for k in range(n_qubits):\n",
    "            if images[-1][k] == 0:\n",
    "                images[-1][k] = algorithm_globals.random.uniform(0, np.pi / 4)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# -------------------------\n",
    "# Build QCNN for arbitrary n_qubits (power of two), measuring the final pooled qubit\n",
    "# -------------------------\n",
    "def build_qcnn(estimator, n_qubits):\n",
    "    _require_power_of_two(n_qubits)\n",
    "\n",
    "    feature_map = ZFeatureMap(n_qubits)\n",
    "\n",
    "    ansatz = QuantumCircuit(n_qubits, name=\"Ansatz\")\n",
    "\n",
    "    # \"active\" holds the absolute indices of the current working block\n",
    "    active = list(range(n_qubits))\n",
    "    stage = 1\n",
    "    while len(active) > 1:\n",
    "        # Convolution over the active block\n",
    "        ansatz.compose(conv_layer(len(active), f\"c{stage}\"), active, inplace=True)\n",
    "\n",
    "        # Pool first half into second half within the active block\n",
    "        half = len(active) // 2\n",
    "        sources_local = list(range(0, half))\n",
    "        sinks_local   = list(range(half, len(active)))\n",
    "        ansatz.compose(pool_layer(sources_local, sinks_local, f\"p{stage}\"), active, inplace=True)\n",
    "\n",
    "        # Next stage works on the sinks (second half)\n",
    "        active = active[half:]\n",
    "        stage += 1\n",
    "\n",
    "    readout_qubit = active[0]  # single remaining qubit\n",
    "    # Construct observable with Z on readout, I elsewhere\n",
    "    obs = [\"I\"] * n_qubits\n",
    "    obs[readout_qubit] = \"Z\"\n",
    "    observable = SparsePauliOp.from_list([(\"\".join(obs), 1)])\n",
    "\n",
    "    circuit = QuantumCircuit(n_qubits)\n",
    "    circuit.compose(feature_map, range(n_qubits), inplace=True)\n",
    "    circuit.compose(ansatz, range(n_qubits), inplace=True)\n",
    "\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=circuit.decompose(),\n",
    "        observables=observable,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        estimator=estimator,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "# -------------------------\n",
    "# One trial\n",
    "# -------------------------\n",
    "def run_trial(seed, n_qubits=8, num_images=200, maxiter=200, estimator=None, dataset=None,\n",
    "              split_random_state=None, optimizer_kind=\"COBYLA\"):\n",
    "    _require_power_of_two(n_qubits)\n",
    "    algorithm_globals.random_seed = int(seed)\n",
    "    rng = np.random.default_rng(int(seed))\n",
    "\n",
    "    # dataset (fresh or fixed)\n",
    "    if dataset is None:\n",
    "        images, labels = generate_dataset(num_images, n_qubits)\n",
    "    else:\n",
    "        images, labels = dataset\n",
    "\n",
    "    rs = split_random_state if split_random_state is not None else int(seed)\n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(\n",
    "        images, labels, test_size=0.30, random_state=rs, stratify=labels\n",
    "    )\n",
    "\n",
    "    qnn = build_qcnn(estimator or Estimator(), n_qubits)\n",
    "    init = rng.uniform(-np.pi, np.pi, qnn.num_weights)\n",
    "\n",
    "    # pick optimizer\n",
    "    if optimizer_kind == \"COBYLA\":\n",
    "        optimizer = COBYLA(maxiter=maxiter)\n",
    "    else:\n",
    "        try:\n",
    "            from qiskit_algorithms.optimizers import SPSA, L_BFGS_B\n",
    "        except Exception:\n",
    "            from qiskit.algorithms.optimizers import SPSA, L_BFGS_B\n",
    "        optimizer = {\"SPSA\": SPSA(maxiter=maxiter),\n",
    "                     \"L_BFGS_B\": L_BFGS_B(maxiter=maxiter)}.get(optimizer_kind, COBYLA(maxiter=maxiter))\n",
    "\n",
    "    clf = NeuralNetworkClassifier(qnn, optimizer=optimizer, initial_point=init, callback=None)\n",
    "\n",
    "    xtr, ytr = np.asarray(x_tr), np.asarray(y_tr)\n",
    "    clf.fit(xtr, ytr)\n",
    "\n",
    "    train_acc = float(clf.score(xtr, ytr))\n",
    "    xte, yte = np.asarray(x_te), np.asarray(y_te)\n",
    "    test_acc  = float(clf.score(xte, yte))\n",
    "\n",
    "    return {\"seed\": int(seed), \"train_acc\": train_acc, \"test_acc\": test_acc}\n",
    "\n",
    "# -------------------------\n",
    "# Many trials + histogram + CSV\n",
    "# -------------------------\n",
    "def run_many(n_trials=10, n_qubits=8, num_images=200, maxiter=200, vary_dataset=True, vary_split=True,\n",
    "             optimizer_kind=\"COBYLA\", save_csv_path=None, show_hist=True):\n",
    "    _require_power_of_two(n_qubits)\n",
    "    est = Estimator()\n",
    "    results = []\n",
    "\n",
    "    fixed_dataset = None\n",
    "    if not vary_dataset:\n",
    "        fixed_dataset = generate_dataset(num_images, n_qubits)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for i in range(n_trials):\n",
    "        seed = 10000 + i\n",
    "        dataset = None if vary_dataset else fixed_dataset\n",
    "        split_rs = (seed if vary_split else 246)\n",
    "        res = run_trial(seed, n_qubits, num_images, maxiter, est, dataset, split_rs, optimizer_kind)\n",
    "        results.append(res)\n",
    "        print(f\"[{i+1}/{n_trials}] seed={seed} train={res['train_acc']:.3f} test={res['test_acc']:.3f}\")\n",
    "\n",
    "    test_accs = np.array([r[\"test_acc\"] for r in results])\n",
    "    train_accs = np.array([r[\"train_acc\"] for r in results])\n",
    "\n",
    "    print(f\"\\nTrials: {n_trials} | elapsed: {time.time()-t0:.1f}s\")\n",
    "    print(f\"Test acc  mean={test_accs.mean():.3f}  std={test_accs.std(ddof=1):.3f}  \"\n",
    "          f\"min={test_accs.min():.3f}  max={test_accs.max():.3f}\")\n",
    "    print(f\"Train acc mean={train_accs.mean():.3f}  std={train_accs.std(ddof=1):.3f}  \"\n",
    "          f\"min={train_accs.min():.3f}  max={train_accs.max():.3f}\")\n",
    "\n",
    "    if show_hist:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.hist(test_accs, bins=10)\n",
    "        plt.xlabel(\"Test Accuracy\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(f\"Distribution of Test Accuracy (n={n_trials}, {n_qubits} qubits)\")\n",
    "        plt.show()\n",
    "\n",
    "    # --- CSV save ---\n",
    "    if save_csv_path:\n",
    "        fieldnames = [\"trial\", \"seed\", \"train_acc\", \"test_acc\",\n",
    "                      \"n_qubits\", \"num_images\", \"maxiter\", \"vary_dataset\", \"vary_split\", \"optimizer\"]\n",
    "        with open(save_csv_path, \"w\", newline=\"\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            w.writeheader()\n",
    "            for i, r in enumerate(results, start=1):\n",
    "                w.writerow({\n",
    "                    \"trial\": i,\n",
    "                    \"seed\": r[\"seed\"],\n",
    "                    \"train_acc\": float(r[\"train_acc\"]),\n",
    "                    \"test_acc\": float(r[\"test_acc\"]),\n",
    "                    \"n_qubits\": int(n_qubits),\n",
    "                    \"num_images\": int(num_images),\n",
    "                    \"maxiter\": int(maxiter),\n",
    "                    \"vary_dataset\": bool(vary_dataset),\n",
    "                    \"vary_split\": bool(vary_split),\n",
    "                    \"optimizer\": str(optimizer_kind),\n",
    "                })\n",
    "        print(f\"Saved results to {save_csv_path}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444ffae-3058-4789-9da2-4102eab2292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
     ]
    }
   ],
   "source": [
    "results = run_many(\n",
    "    n_trials=3, n_qubits=8, num_images=200, maxiter=200,\n",
    "    vary_dataset=True, vary_split=True,\n",
    "    save_csv_path=\"16qbit_50iter.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba15e2-bf27-488f-87f4-520554169d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
